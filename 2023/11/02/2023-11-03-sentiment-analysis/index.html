<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.0.2">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png">
  <link rel="mask-icon" href="/images/favicon.png" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"mikelhsia.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":"valine","storage":true,"lazyload":false,"nav":null,"activeClass":"valine"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Photo by Shutterstock   In this article, we will discuss how sentiment analysis impacts the financial market, the basics of NLP(Natural Language Processing), and showcase how to process the financ">
<meta property="og:type" content="article">
<meta property="og:title" content="Sentiment analysis lesson 101 and hands-on practice session">
<meta property="og:url" content="http://mikelhsia.github.io/2023/11/02/2023-11-03-sentiment-analysis/index.html">
<meta property="og:site_name" content="Michael&#39;s blog">
<meta property="og:description" content="Photo by Shutterstock   In this article, we will discuss how sentiment analysis impacts the financial market, the basics of NLP(Natural Language Processing), and showcase how to process the financ">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://mikelhsia.github.io/2023/11/02/2023-11-03-sentiment-analysis/cover.png">
<meta property="og:image" content="http://mikelhsia.github.io/2023/11/02/2023-11-03-sentiment-analysis/contemplating.png">
<meta property="og:image" content="http://mikelhsia.github.io/2023/11/02/2023-11-03-sentiment-analysis/NLP_process.png">
<meta property="og:image" content="http://mikelhsia.github.io/2023/11/02/2023-11-03-sentiment-analysis/tokenization.png">
<meta property="og:image" content="http://mikelhsia.github.io/2023/11/02/2023-11-03-sentiment-analysis/stem_n_lemmi.png">
<meta property="og:image" content="http://mikelhsia.github.io/2023/11/02/2023-11-03-sentiment-analysis/stem_n_lemmi_2.png">
<meta property="og:image" content="http://mikelhsia.github.io/2023/11/02/2023-11-03-sentiment-analysis/vader_scores.png">
<meta property="og:image" content="http://mikelhsia.github.io/2023/11/02/2023-11-03-sentiment-analysis/step_1_for_sentiment_analysis.png">
<meta property="og:image" content="http://mikelhsia.github.io/2023/11/02/2023-11-03-sentiment-analysis/step_2_for_sentiment_analysis.png">
<meta property="og:image" content="http://mikelhsia.github.io/2023/11/02/2023-11-03-sentiment-analysis/step_3_for_sentiment_analysis.png">
<meta property="og:image" content="http://mikelhsia.github.io/2023/11/02/2023-11-03-sentiment-analysis/step_4_for_sentiment_analysis.png">
<meta property="article:published_time" content="2023-11-02T03:24:37.000Z">
<meta property="article:modified_time" content="2023-11-10T03:52:50.138Z">
<meta property="article:author" content="Michael Hsia">
<meta property="article:tag" content="Scrapy">
<meta property="article:tag" content="Research">
<meta property="article:tag" content="Technical Analysis">
<meta property="article:tag" content="Python3">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://mikelhsia.github.io/2023/11/02/2023-11-03-sentiment-analysis/cover.png">

<link rel="canonical" href="http://mikelhsia.github.io/2023/11/02/2023-11-03-sentiment-analysis/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Sentiment analysis lesson 101 and hands-on practice session | Michael's blog</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-177399736-1"></script>
    <script>
      if (CONFIG.hostname === location.hostname) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-177399736-1');
      }
    </script>






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Michael's blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Michael's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Life-long Learning</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>About</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://mikelhsia.github.io/2023/11/02/2023-11-03-sentiment-analysis/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Michael Hsia">
      <meta itemprop="description" content="Free your potential with learning for the rest of your life">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Michael's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Sentiment analysis lesson 101 and hands-on practice session
        </h1>

        

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-11-02 11:24:37" itemprop="dateCreated datePublished" datetime="2023-11-02T11:24:37+08:00">2023-11-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-11-10 11:52:50" itemprop="dateModified" datetime="2023-11-10T11:52:50+08:00">2023-11-10</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Factor-Analysis/" itemprop="url" rel="index"><span itemprop="name">Factor Analysis</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Factor-Analysis/How2/" itemprop="url" rel="index"><span itemprop="name">How2</span></a>
                </span>
            </span>

          
            <span id="/2023/11/02/2023-11-03-sentiment-analysis/" class="post-meta-item leancloud_visitors" data-flag-title="Sentiment analysis lesson 101 and hands-on practice session" title="Views">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2023/11/02/2023-11-03-sentiment-analysis/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/11/02/2023-11-03-sentiment-analysis/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <img data-src="/2023/11/02/2023-11-03-sentiment-analysis/cover.png" class="" width="800">
<p style="text-align:center; color: grey;">
  <i>Photo by <a target="_blank" rel="noopener" href='https://www.shutterstock.com/'>Shutterstock</a></i>
</p>

<p>In this article, we will discuss how sentiment analysis impacts the financial market, the basics of NLP(<em>Natural Language Processing</em>), and showcase how to process the financial headlines by batch to generate an indicator of the market sentiment.</p>
<a id="more"></a>
<hr>
<p>Become a <a target="_blank" rel="noopener" href="https://medium.com/@mikelhsia/membership">Medium member</a> to continue learning without limits. I’ll receive a small portion of your membership fee if you use the following link, at no extra cost to you.</p>
<blockquote>
<p>If you enjoy reading this and my other articles, feel free to <a src='https://medium.com/@mikelhsia/membership'> join Medium membership program</a> to read more about Quantitative Trading Strategy.</p>
</blockquote>
<hr>
<h1 id="What-is-Sentiment-Analysis"><a href="#What-is-Sentiment-Analysis" class="headerlink" title="What is Sentiment Analysis"></a>What is Sentiment Analysis</h1><p>Imagine this,</p>
<blockquote>
<p>You are a top-notch trader on the Wall Street. One day morning, you were reading the newspaper while sipping a cup of Americano from your favorite mug. You’re enjoying the beautiful sunlight shed on you. Suddenly, one piece of news grabbed your attention. The news seemed to be talking about the newly released product and financial forecast of the company. After reading the whole piece, the pessimistic tone throughout the article started worrying you. You stroke your chin and started contemplating, “Maybe I should dump the shares that I purchased yesterday”…</p>
</blockquote>
<img data-src="/2023/11/02/2023-11-03-sentiment-analysis/contemplating.png" class="" width="600">
<p style="text-align:center; color: grey;">
  <i>Contemplation photo by <a target="_blank" rel="noopener" href='https://medium.com/r/?url=https%3A%2F%2Funsplash.com%2F%40dariusbashar%3Futm_source%3Dmedium%26utm_medium%3Dreferral'>Darius Bashar</a> on <a target="_blank" rel="noopener" href='https://medium.com/r/?url=https%3A%2F%2Funsplash.com%3Futm_source%3Dmedium%26utm_medium%3Dreferral'>Unsplash</a></i>
</p>

<p>This is the perfect example of sentiment analysis. When you receive a piece of information, you start reading it and conducting analysis not just based on the intel hidden inside the information, but you also make the judgment using the sentiment you get from the words and punctuation in the sentence. Sentiment analysis is essentially the process of analyzing digital text to determine whether the emotional implication of the message is positive, negative, or neutral. The sentiment you extract from the text can help you further improve the accuracy of your decision-making process.</p>
<h1 id="What-is-the-application-of-Sentiment-Analysis-in-the-financial-market"><a href="#What-is-the-application-of-Sentiment-Analysis-in-the-financial-market" class="headerlink" title="What is the application of Sentiment Analysis in the financial market"></a>What is the application of Sentiment Analysis in the financial market</h1><p>The emotions of the investors mostly drive the financial market and they are usually influenced by the news released by the companies or the reporters. As the technology evolved, we’re in an information explosion era that the text-format intel will need to be processed by machine rather than by manpower. Therefore, there are already a lot of companies and organizations using machines to process the company press release, annual financial report, or even forum comments to build up a clear idea of where the public opinions are heading. In order to enable machines to do that, there are a lot of linguistic techniques that need to be applied. Thankfully, we already have a lot of mature technology and theories out there for us to choose from. All these tools, techniques, and theories are now under the hood of <strong>“NLP” (Natural Language Processing)</strong>.</p>
<h1 id="NLP-Introduction"><a href="#NLP-Introduction" class="headerlink" title="NLP Introduction"></a>NLP Introduction</h1><p>NLP is an interdisciplinary realm of computer science and linguistics, and the scholars in this field are dedicated to summarizing the languages we use into linguistic rules and then teaching computers to understand and even speak the languages. Currently, there are already AI products built to be able to conduct conversations with humans, such as ChatGPT from OpenAI, Bard from Google, and Claude from Anthropic. These are all state-of-the-art AI products for users to apply to their daily lives. However, we won’t be touching any of these in this article. Instead, we’re going back to the basics using <code>NLTK (Natural Language Tool Kit)</code> to showcase how we can transform a sentence into a number-based sentiment score to help us be better informed than the other retail investors..</p>
<p>As said, the goal is to process our language into the binaries that computers can understand. This is the so-called <strong>vectorizing ofgiven text</strong>. Once the text has been vectorized into a series of numbers, the serialized numbers can be treated as features and fed to the machine-learning model. Then, the following are the things that we get used to, such as feature engineering, model training, and result predicting. Before vectorizing the text, there are several steps to go through as the image demonstrated below:<br><img data-src="/2023/11/02/2023-11-03-sentiment-analysis/NLP_process.png" class="" width="400"></p>
<p style="text-align:center; color: grey;">
  <i>NLP processes to vectorize text</i>
</p>

<h2 id="Tokenization"><a href="#Tokenization" class="headerlink" title="Tokenization"></a>Tokenization</h2><img data-src="/2023/11/02/2023-11-03-sentiment-analysis/tokenization.png" class="" width="800">
<p style="text-align:center; color: grey;">
  <i>NLP processes: Tokenization</i>
</p>

<p>Tokenization, as the name suggests, is to break the sentence into words and to standardize these words into tokens that can be treated unanimously with the following steps:</p>
<p><strong>Split the document/sentence word by word</strong></p>
<p>This would be the very first step to process the text-based document input.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"></span><br><span class="line"><span class="comment"># This is the lexicon for processing text. We&#x27;re going to talk about it later</span></span><br><span class="line">nltk.download(<span class="string">&#x27;punkt&#x27;</span>)</span><br><span class="line"></span><br><span class="line">corporas = <span class="string">&quot;AMD’s Q3 earnings report exceeded Wall Street&#x27;s expectations. \</span></span><br><span class="line"><span class="string">Its growth indicates the PC market has finally bottomed out. ......&quot;</span></span><br><span class="line"></span><br><span class="line">print(nltk.sent_tokenize(corporas))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>[<span class="string">&quot;AMD’s Q3 earnings report exceeded Wall Street&#x27;s expectations.&quot;</span>,</span><br><span class="line"> <span class="string">&#x27;Its growth indicates the PC market has finally bottomed out.&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;......&#x27;</span>]</span><br><span class="line"></span><br><span class="line">print(nltk.word_tokenize(corporas))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>[<span class="string">&#x27;AMD&#x27;</span>, <span class="string">&#x27;’&#x27;</span>, <span class="string">&#x27;s&#x27;</span>, <span class="string">&#x27;Q3&#x27;</span>, <span class="string">&#x27;earnings&#x27;</span>, <span class="string">&#x27;report&#x27;</span>, <span class="string">&#x27;exceeded&#x27;</span>, <span class="string">&#x27;Wall&#x27;</span>, <span class="string">&#x27;Street&#x27;</span>, <span class="string">&quot;&#x27;s&quot;</span>, <span class="string">&#x27;expectations&#x27;</span>, <span class="string">&#x27;.&#x27;</span>, <span class="string">&#x27;Its&#x27;</span>, <span class="string">&#x27;growth&#x27;</span>, <span class="string">&#x27;indicates&#x27;</span>, <span class="string">&#x27;the&#x27;</span>, <span class="string">&#x27;PC&#x27;</span>, <span class="string">&#x27;market&#x27;</span>, <span class="string">&#x27;has&#x27;</span>, <span class="string">&#x27;finally&#x27;</span>, <span class="string">&#x27;bottomed&#x27;</span>, <span class="string">&#x27;out&#x27;</span>, <span class="string">&#x27;.&#x27;</span>, <span class="string">&#x27;......&#x27;</span>]</span><br></pre></td></tr></table></figure></p>
<p>Now you can see that all the words and punctuations are split into individual words. However, these words are not yet ready as there are irregular symbols or characters in the list that actually have no meaning at all. Therefore, we need to remove them from our token list.</p>
<p><strong>Remove symbols and punctuation</strong></p>
<p>In the token list above, we see a lot of punctuations such as <code>&#39;</code>, <code>.</code>, or <code>...</code> scattered here and there throughout the list. Even though they do mean something when they are combined into a sentence, removing them actually won’t prevent us or the machine from understanding the general structure of the sentence.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tokens = [x <span class="keyword">for</span> x <span class="keyword">in</span> nltk.word_tokenize(corporas) <span class="keyword">if</span> x.isalpha()]</span><br><span class="line">print(tokens)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>[<span class="string">&#x27;AMD&#x27;</span>, <span class="string">&#x27;s&#x27;</span>, <span class="string">&#x27;earnings&#x27;</span>, <span class="string">&#x27;report&#x27;</span>, <span class="string">&#x27;exceeded&#x27;</span>, <span class="string">&#x27;Wall&#x27;</span>, <span class="string">&#x27;Street&#x27;</span>, <span class="string">&#x27;expectations&#x27;</span>, <span class="string">&#x27;Its&#x27;</span>, <span class="string">&#x27;growth&#x27;</span>, <span class="string">&#x27;indicates&#x27;</span>, <span class="string">&#x27;the&#x27;</span>, <span class="string">&#x27;PC&#x27;</span>, <span class="string">&#x27;market&#x27;</span>, <span class="string">&#x27;has&#x27;</span>, <span class="string">&#x27;finally&#x27;</span>, <span class="string">&#x27;bottomed&#x27;</span>, <span class="string">&#x27;out&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p><strong>Remove stop words</strong></p>
<p>Stop words are a set of common words that add much meaning to a sentence. For example, if you want to know <em>“how to cook a piece of steak with a oven”</em>, you probably google with keywords <code>cook</code>, <code>steak</code>, and <code>oven</code>. <code>How</code>, <code>to</code>, <code>a</code>, <code>of</code>, and <code>with</code> would be considered stop words as they contain less information than the rest of the words. The stop words are actually used in every language (<em>but maybe not in programming languages lol</em>).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> stopwords</span><br><span class="line"></span><br><span class="line"><span class="comment"># Again, another lexicon that contains all the stop words</span></span><br><span class="line">nltk.download(<span class="string">&#x27;stopwords&#x27;</span>)</span><br><span class="line"></span><br><span class="line">stop_words = set(stopwords.words(<span class="string">&#x27;english&#x27;</span>))</span><br><span class="line">tokens_wo_stop_words = [x <span class="keyword">for</span> x <span class="keyword">in</span> tokens <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> stop_words]</span><br><span class="line">print(tokens_wo_stop_words)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>[<span class="string">&#x27;AMD&#x27;</span>, <span class="string">&#x27;earnings&#x27;</span>, <span class="string">&#x27;report&#x27;</span>, <span class="string">&#x27;exceeded&#x27;</span>, <span class="string">&#x27;Wall&#x27;</span>, <span class="string">&#x27;Street&#x27;</span>, <span class="string">&#x27;expectations&#x27;</span>, <span class="string">&#x27;Its&#x27;</span>, <span class="string">&#x27;growth&#x27;</span>, <span class="string">&#x27;indicates&#x27;</span>, <span class="string">&#x27;PC&#x27;</span>, <span class="string">&#x27;market&#x27;</span>, <span class="string">&#x27;finally&#x27;</span>, <span class="string">&#x27;bottomed&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>See! The tokens now look more unified, and would not prevent us from understanding the exact meaning of this sentence. Here we finish the first step of the processing.</p>
<h2 id="Stemming-amp-Lemmatization"><a href="#Stemming-amp-Lemmatization" class="headerlink" title="Stemming &amp; Lemmatization"></a>Stemming &amp; Lemmatization</h2><img data-src="/2023/11/02/2023-11-03-sentiment-analysis/stem_n_lemmi.png" class="" width="800">
<p style="text-align:center; color: grey;">
  <i>NLP processes: Stemming and Lemmatization</i>
</p>

<p>The English language has many variations of a single common root form. For example, the word <code>love</code> has forms of <em>loves (verb.), loved(verb.), loving(adj.), loves(n)</em>. These variations do help human beings comprehend the context of the speakers’ intentions but inevitably create ambiguity for the machine-learning model to grasp the key point in the document. Therefore, it’s crucial to further process these variations and then convert them to an identical form that won’t confuse the machine learning model. <code>Stemming</code> or <code>lemmatization</code> are the techniques that facilitate finding the common root form of word variations in different ways, but ultimately they both aim to achieve the same goal.</p>
<p><strong>Lexicons</strong><br>First of all, let’s talk about lexicons. Lexicons are the fundamentals of the stemming and lemmatization techniques. It is like a dictionary to look up when finding the root form of a word variation. Therefore, choosing the right lexicons to use is very crucial for processing the words in the given document. <strong>LIWC</strong>, <strong>Harvard’s General Inquirer</strong>, <strong>SeticNet</strong>, and <strong>SentiWordNet</strong> are the most famous lexicons. <strong>Loughran-McDonald Master Dictionary</strong> is one of the most popular economy lexicons. <strong>SentiBigNomics</strong> is a detailed financial dictionary specialized in sentiment analysis. There are around 7300 terms and root forms documented in this lexicon. Also, if you’re looking to conduct sentiment analysis against the bio-medical paper, <strong>WordNet for Medical Events (WME)</strong> could be your better choice.</p>
<p><strong>Stemming</strong><br>Stemming is a process to reduce the morphological affixes from word variations, leaving only the word stem. The grammatical role, tense, and derivational morphology will be stripped away, leaving only the stem of the word, which is the common root. For example, both <code>loves</code> and <code>loving</code> will be stemmed back to the root form <code>love</code>. However, stemming has its dark side that sometimes will backfire. The words <code>universal</code>, <code>university</code>, and <code>universe</code> have different meanings, but share the same root form <code>univers</code> if you adopt the stemming method. This is the price you have to pay because stemming offers a faster and easier way to extract text features.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> PorterStemmer</span><br><span class="line">ps = PorterStemmer()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> w <span class="keyword">in</span> tokens_wo_stop_words:</span><br><span class="line">    print(<span class="string">f&#x27;<span class="subst">&#123;w&#125;</span>: <span class="subst">&#123;ps.stem(w)&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>AMD: amd</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>earnings: earn</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>report: report</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>exceeded: exceed</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Wall: wall</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Street: street</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>expectations: expect</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Its: it</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>growth: growth</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>indicates: indic</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>PC: pc</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>market: market</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">finally</span>: final</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bottomed: bottom</span><br></pre></td></tr></table></figure>
<p><strong>Lemmatization</strong><br>On the contrary, lemmatization can better discover the root form of the word variations with the cost of sacrificing the performance of speed. Lemmatization uses a thicker lexicon to compare and match with to find out the root form. Hence, it’ll return a more accurate word compared to stemming. Also, lemmatization also takes the part of speech into consideration. For example, lemmatize <code>saw</code> will get you <code>see</code> if you treat it as a verb and <code>saw</code> if you treat it as a noun.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> WordNetLemmatizer</span><br><span class="line"></span><br><span class="line">nltk.download(<span class="string">&#x27;wordnet&#x27;</span>)</span><br><span class="line">nltk.download(<span class="string">&#x27;omw-1.4&#x27;</span>)</span><br><span class="line"></span><br><span class="line">lemmatizer = WordNetLemmatizer()</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;AMD: <span class="subst">&#123;lemmatizer.lemmatize(<span class="string">&quot;AMD&quot;</span>, pos=<span class="string">&quot;n&quot;</span>)&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>AMD: AMD</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;earnings: <span class="subst">&#123;lemmatizer.lemmatize(<span class="string">&quot;earnings&quot;</span>, pos=<span class="string">&quot;n&quot;</span>)&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>earnings: earnings</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;report: <span class="subst">&#123;lemmatizer.lemmatize(<span class="string">&quot;report&quot;</span>, pos=<span class="string">&quot;n&quot;</span>)&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>report: report</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;exceeded: <span class="subst">&#123;lemmatizer.lemmatize(<span class="string">&quot;exceeded&quot;</span>, pos=<span class="string">&quot;v&quot;</span>)&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>exceeded: exceed</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;Wall: <span class="subst">&#123;lemmatizer.lemmatize(<span class="string">&quot;Wall&quot;</span>, pos=<span class="string">&quot;n&quot;</span>)&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Wall: Wall</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;Street: <span class="subst">&#123;lemmatizer.lemmatize(<span class="string">&quot;Street&quot;</span>, pos=<span class="string">&quot;n&quot;</span>)&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Street: Street</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;expectations: <span class="subst">&#123;lemmatizer.lemmatize(<span class="string">&quot;expectations&quot;</span>, pos=<span class="string">&quot;n&quot;</span>)&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>expectations: expectation</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;Its: <span class="subst">&#123;lemmatizer.lemmatize(<span class="string">&quot;Its&quot;</span>, pos=<span class="string">&quot;n&quot;</span>)&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Its: Its</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;growth: <span class="subst">&#123;lemmatizer.lemmatize(<span class="string">&quot;growth&quot;</span>, pos=<span class="string">&quot;n&quot;</span>)&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>growth: growth</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;indicates: <span class="subst">&#123;lemmatizer.lemmatize(<span class="string">&quot;indicates&quot;</span>, pos=<span class="string">&quot;v&quot;</span>)&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>indicates: indicate</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;PC: <span class="subst">&#123;lemmatizer.lemmatize(<span class="string">&quot;PC&quot;</span>, pos=<span class="string">&quot;n&quot;</span>)&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>PC: PC</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;market: <span class="subst">&#123;lemmatizer.lemmatize(<span class="string">&quot;market&quot;</span>, pos=<span class="string">&quot;n&quot;</span>)&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>market: market</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;finally: <span class="subst">&#123;lemmatizer.lemmatize(<span class="string">&quot;finally&quot;</span>, pos=<span class="string">&quot;r&quot;</span>)&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">finally</span>: <span class="keyword">finally</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;bottomed: <span class="subst">&#123;lemmatizer.lemmatize(<span class="string">&quot;bottomed&quot;</span>, pos=<span class="string">&quot;v&quot;</span>)&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bottomed: bottom</span><br></pre></td></tr></table></figure>
<p>One thing that is worth talking about is, that unless you have faithful confidence knowing your model needs both these techniques come into play, you probably don’t want to use these two techniques at the same time. For example, the stemming method will strip the word <code>saws</code> down to <code>saw</code>, which makes sense because <code>saws</code> is a plural format of the noun <code>saw</code>. If you then try to apply lemmatization to the word <code>saw</code>, you might get <code>see</code> if you didn’t specify it as a noun. So be aware.</p>
<img data-src="/2023/11/02/2023-11-03-sentiment-analysis/stem_n_lemmi_2.png" class="" width="600">
<p style="text-align:center; color: grey;">
  <i>Differences between stemming and lemmatization</i>
</p>

<h2 id="Part-of-speech-tagging"><a href="#Part-of-speech-tagging" class="headerlink" title="Part-of-speech tagging"></a>Part-of-speech tagging</h2><p>After learning the power of lemmatization, you probably wanna ask, <em>“Hey! If I’m going to specify the part of speech of every single word, that is no longer efficient at all”</em>. Worry not. <code>NLTK</code> is well-thought-out and has built this part-of-speech tagging as one of its sub-packages. You simply pass your tokens as parameters into <code>nltk.pos_tag()</code> function and the pre-defined <a target="_blank" rel="noopener" href="https://www.ibm.com/docs/en/wca/3.5.0?topic=analytics-part-speech-tag-sets">part-of-speech tag</a> will be returned together with the tokens as tuples. You can then further define a function to replace the returned pos tag with the simple set of <code>[n, v, adj, adv, conj, ...]</code>, making lemmatization much more easier.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">nltk.download(<span class="string">&#x27;averaged_perceptron_tagger&#x27;</span>)</span><br><span class="line"></span><br><span class="line">nltk.pos_tag(tokens_wo_stop_words)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>[(<span class="string">&#x27;AMD&#x27;</span>, <span class="string">&#x27;NNP&#x27;</span>), (<span class="string">&#x27;earnings&#x27;</span>, <span class="string">&#x27;NNS&#x27;</span>), (<span class="string">&#x27;report&#x27;</span>, <span class="string">&#x27;NN&#x27;</span>), (<span class="string">&#x27;exceeded&#x27;</span>, <span class="string">&#x27;VBD&#x27;</span>), (<span class="string">&#x27;Wall&#x27;</span>, <span class="string">&#x27;NNP&#x27;</span>), (<span class="string">&#x27;Street&#x27;</span>, <span class="string">&#x27;NNP&#x27;</span>), (<span class="string">&#x27;expectations&#x27;</span>, <span class="string">&#x27;NNS&#x27;</span>), (<span class="string">&#x27;Its&#x27;</span>, <span class="string">&#x27;PRP$&#x27;</span>), (<span class="string">&#x27;growth&#x27;</span>, <span class="string">&#x27;NN&#x27;</span>), (<span class="string">&#x27;indicates&#x27;</span>, <span class="string">&#x27;VBZ&#x27;</span>), (<span class="string">&#x27;PC&#x27;</span>, <span class="string">&#x27;NN&#x27;</span>), (<span class="string">&#x27;market&#x27;</span>, <span class="string">&#x27;NN&#x27;</span>), (<span class="string">&#x27;finally&#x27;</span>, <span class="string">&#x27;RB&#x27;</span>), (<span class="string">&#x27;bottomed&#x27;</span>, <span class="string">&#x27;VBD&#x27;</span>)]</span><br></pre></td></tr></table></figure>
<h2 id="NER-Named-Entity-Recognition-and-chunking"><a href="#NER-Named-Entity-Recognition-and-chunking" class="headerlink" title="NER (Named Entity Recognition) and chunking"></a>NER (Named Entity Recognition) and chunking</h2><p>What is NER (Named Entity Recognition)? Easy. Take the <code>New York Statue of Liberty</code> for example. Should we tokenize this into <code>New</code>, <code>York</code>, <code>Statue</code>, <code>of</code>, and <code>Liberty</code>, or should be <code>New York</code> and <code>Statue of Liberty</code> instead? The named entity is the unique name for places, people, things, locations, etc. This combination of words shouldn’t be treated as multiple tokens. Instead, it should be treated as one token. That’s why we need to regroup the words and find out the named entities, reducing the chances of confusing our following steps.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">nltk.download(<span class="string">&#x27;maxent_ne_chunker&#x27;</span>)</span><br><span class="line">nltk.download(<span class="string">&#x27;words&#x27;</span>)</span><br><span class="line"></span><br><span class="line">tagged_token = nltk.pos_tag(tokens_wo_stop_words)</span><br><span class="line">nltk.chunk.ne_chunk(tagged_token)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> nltk.chunk.ne_chunk(tagged_token):</span><br><span class="line">  <span class="keyword">if</span> hasattr(chunk, <span class="string">&#x27;label&#x27;</span>):</span><br><span class="line">    print(chunk.label(), <span class="string">&#x27; &#x27;</span>.join(c[<span class="number">0</span>] <span class="keyword">for</span> c <span class="keyword">in</span> chunk))</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>FACILITY Wall Street</span><br><span class="line"></span><br><span class="line">processed_token = [(<span class="string">&#x27; &#x27;</span>.join(c[<span class="number">0</span>] <span class="keyword">for</span> c <span class="keyword">in</span> chunk), chunk.label()) <span class="keyword">if</span> hasattr(chunk, <span class="string">&#x27;label&#x27;</span>) <span class="keyword">else</span> chunk <span class="keyword">for</span> chunk <span class="keyword">in</span> nltk.chunk.ne_chunk(tagged_token)]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>[(<span class="string">&#x27;AMD&#x27;</span>, <span class="string">&#x27;NNP&#x27;</span>), (<span class="string">&#x27;earnings&#x27;</span>, <span class="string">&#x27;NNS&#x27;</span>), (<span class="string">&#x27;report&#x27;</span>, <span class="string">&#x27;NN&#x27;</span>), (<span class="string">&#x27;exceeded&#x27;</span>, <span class="string">&#x27;VBD&#x27;</span>), (<span class="string">&#x27;Wall Street&#x27;</span>, <span class="string">&#x27;FACILITY&#x27;</span>), (<span class="string">&#x27;expectations&#x27;</span>, <span class="string">&#x27;NNS&#x27;</span>), (<span class="string">&#x27;Its&#x27;</span>, <span class="string">&#x27;PRP$&#x27;</span>), (<span class="string">&#x27;growth&#x27;</span>, <span class="string">&#x27;NN&#x27;</span>), (<span class="string">&#x27;indicates&#x27;</span>, <span class="string">&#x27;VBZ&#x27;</span>), (<span class="string">&#x27;PC&#x27;</span>, <span class="string">&#x27;NN&#x27;</span>), (<span class="string">&#x27;market&#x27;</span>, <span class="string">&#x27;NN&#x27;</span>), (<span class="string">&#x27;finally&#x27;</span>, <span class="string">&#x27;RB&#x27;</span>), (<span class="string">&#x27;bottomed&#x27;</span>, <span class="string">&#x27;VBD&#x27;</span>)]</span><br></pre></td></tr></table></figure>
<p>See! <code>Wall Street</code> has been put together into one word as a named entity.</p>
<hr>
<p><strong><em>OK!</em></strong></p>
<p>I’m going to stop it right here. After all, we don’t need all the steps in place to conduct a simple sentiment analysis. We’ll now jump right into the simple sentiment analysis tool to evaluate the emotional implication of the news headline. However, if you want to know more details about the details of the rest of these steps and also how to apply them in the stock market, feel free to leave a message to me.</p>
<h1 id="VADER-Valence-Aware-Dictionary-and-sEntiment-Reasoner"><a href="#VADER-Valence-Aware-Dictionary-and-sEntiment-Reasoner" class="headerlink" title="VADER (Valence Aware Dictionary and sEntiment Reasoner)"></a>VADER (Valence Aware Dictionary and sEntiment Reasoner)</h1><p><code>VADER</code> is a model built in <code>NLTK</code> package that aims to evaluate the emotional intensity of a sentence. <code>VADER</code> not only determines whether a sentence is positive or negative, but it also evaluates the intensity level of the sentence, judging how positive or negative is a given sentence. Here are a few more things about <code>VADER</code>:</p>
<ul>
<li><code>VADER</code> returns four values for each sentence evaluation: positive level, negative level, neutral level, and compound score.</li>
<li>It takes into account of the emotional impact of special punctuations like <code>!!!</code> and <code>!?</code> and also the emojis such as <code>:)</code> and <code>;(</code>.</li>
<li>It also factors in the impact of the all-capitalized characters which enhance or dampen the emotional implication of a sentence.</li>
<li>It’s fast as it doesn’t need to train any model before using it</li>
<li>It’s best suited for the language used in social media because of its excellence in analyzing emojis and unconventional punctuation.</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">%-)    -1.5    1.43178    [-2, 0, -2, -2, -1, 2, -2, -3, -2, -3]</span><br><span class="line">&amp;-:    -0.4    1.42829    [-3, -1, 0, 0, -1, -1, -1, 2, -1, 2]</span><br><span class="line">...</span><br><span class="line">advantaged    1.4    0.91652    [1, 0, 3, 0, 1, 1, 2, 2, 2, 2]</span><br><span class="line">advantageous    1.5    0.67082    [2, 0, 2, 2, 2, 1, 1, 1, 2, 2]</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p style="text-align:center; color: grey;">
  <i><b><a target="_blank" rel="noopener" href='https://github.com/cjhutto/vaderSentiment/blob/master/vaderSentiment/vader_lexicon.txt'>vader_lexicon.txt</a></b> is used for finding the corresponding score of a word or a punctuation</i>
</p>

<p>The scoring method that <code>VADER</code> used and its source code are relatively straightforward and easy to understand. I would encourage you to spend half an hour to get to know what <code>VADER</code> does when it comes to evaluating the sentiment score. <em>(Check out the <a target="_blank" rel="noopener" href="https://www.nltk.org/_modules/nltk/sentiment/vader.html">VADER source code</a>)</em>.</p>
<img data-src="/2023/11/02/2023-11-03-sentiment-analysis/vader_scores.png" class="" width="600">
<p style="text-align:center; color: grey;">
  <i>A couple of examples of VADER <i>polarity_scores()</i> </i>
</p>

<h1 id="Get-started-with-the-stock-sentiment-analysis"><a href="#Get-started-with-the-stock-sentiment-analysis" class="headerlink" title="Get started with the stock sentiment analysis"></a>Get started with the stock sentiment analysis</h1><p>Let’s get down to business! I’m going to demonstrate how to conduct sentiment analysis with <code>VADER</code> against four stocks: <code>NVDA</code>, <code>AVGO</code>, <code>AMD</code>, <code>BABA</code>. As for the data sources of the news headline, I will scrape from the <a target="_blank" rel="noopener" href="https://finviz.com/quote.ashx?t=amd&amp;p=d">https://finviz.com/</a> as suggested by the author of <a target="_blank" rel="noopener" href="https://medium.datadriveninvestor.com/sentiment-analysis-of-stocks-from-financial-news-using-python-82ebdcefb638">this article</a>.</p>
<h2 id="Step-1-Global-variables"><a href="#Step-1-Global-variables" class="headerlink" title="Step 1. Global variables"></a>Step 1. Global variables</h2><p>First, let’s import the libraries we need, and define the tickers that we’re going to look into.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">from</span> nltk.sentiment.vader <span class="keyword">import</span> SentimentIntensityAnalyzer</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define the ticker list</span></span><br><span class="line">tickers_list = [<span class="string">&#x27;NVDA&#x27;</span>, <span class="string">&#x27;AVGO&#x27;</span>, <span class="string">&#x27;AMD&#x27;</span>, <span class="string">&#x27;BABA&#x27;</span>]</span><br></pre></td></tr></table></figure>
<h2 id="Step-2-Fetch-the-headlines-of-the-tickers"><a href="#Step-2-Fetch-the-headlines-of-the-tickers" class="headerlink" title="Step 2. Fetch the headlines of the tickers"></a>Step 2. Fetch the headlines of the tickers</h2><p>In this step, we use <code>BeautifulSoup</code> and <code>requests</code> to scrape the news headline from <a target="_blank" rel="noopener" href="https://finviz.com/">https://finviz.com/</a>. After you scrape the headlines and tuck them into the pd.DataFrame, you will notice that most cells in the <code>Date</code> column are actually empty. That is because the date format in the <a target="_blank" rel="noopener" href="https://finviz.com/">https://finviz.com/</a> causes this issue. Hence, we need to further process the data in <code>Date</code> column and extract the time data to fill in the <code>Time</code> column. Once that is done properly, we can now concatenate all the scraped headlines to produce a complete headline table.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">news = pd.DataFrame()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> ticker <span class="keyword">in</span> tickers_list:</span><br><span class="line">    url = <span class="string">f&#x27;https://finviz.com/quote.ashx?t=<span class="subst">&#123;ticker&#125;</span>&amp;p=d&#x27;</span></span><br><span class="line">    ret = requests.get(</span><br><span class="line">        url,</span><br><span class="line">        headers=&#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36&#x27;</span>&#125;,</span><br><span class="line">    )</span><br><span class="line">    html = BeautifulSoup(ret.content, <span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        df = pd.read_html(</span><br><span class="line">            str(html),</span><br><span class="line">            attrs=&#123;<span class="string">&#x27;class&#x27;</span>: <span class="string">&#x27;fullview-news-outer&#x27;</span>&#125;</span><br><span class="line">        )[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># print(f&quot;&#123;ticker&#125; Done&quot;)</span></span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        print(<span class="string">f&quot;<span class="subst">&#123;ticker&#125;</span> No news found&quot;</span>)</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    df.columns = [<span class="string">&#x27;Date&#x27;</span>, <span class="string">&#x27;Headline&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Process date and time columns to make sure this is filled in every headline each row</span></span><br><span class="line">    dateNTime = df.Date.apply(<span class="keyword">lambda</span> x: <span class="string">&#x27;,&#x27;</span>+x <span class="keyword">if</span> len(x)&lt;<span class="number">8</span> <span class="keyword">else</span> x).str.split(<span class="string">r&#x27; |,&#x27;</span>, expand = <span class="literal">True</span>).replace(<span class="string">&quot;&quot;</span>, <span class="literal">None</span>).ffill()</span><br><span class="line">    df = pd.merge(df, dateNTime, right_index=<span class="literal">True</span>, left_index=<span class="literal">True</span>).drop(<span class="string">&#x27;Date&#x27;</span>, axis=<span class="number">1</span>).rename(columns=&#123;<span class="number">0</span>:<span class="string">&#x27;Date&#x27;</span>, <span class="number">1</span>:<span class="string">&#x27;Time&#x27;</span>&#125;)</span><br><span class="line">    df.loc[:, <span class="string">&#x27;Date&#x27;</span>][df.loc[:,<span class="string">&#x27;Date&#x27;</span>]==<span class="string">&#x27;Today&#x27;</span>] = str(datetime.now().date())</span><br><span class="line">    df.Date = pd.to_datetime(df.Date)</span><br><span class="line">    df.Time = pd.to_datetime(df.Time).dt.time</span><br><span class="line">    df = df[df[<span class="string">&quot;Headline&quot;</span>].str.contains(<span class="string">&quot;Loading.&quot;</span>) == <span class="literal">False</span>].loc[:, [<span class="string">&#x27;Date&#x27;</span>, <span class="string">&#x27;Time&#x27;</span>, <span class="string">&#x27;Headline&#x27;</span>]]</span><br><span class="line">    df[<span class="string">&quot;Date&quot;</span>] = df[<span class="string">&quot;Date&quot;</span>].dt.date</span><br><span class="line"></span><br><span class="line">    df[<span class="string">&quot;Ticker&quot;</span>] = ticker</span><br><span class="line">    news = pd.concat([news, df], ignore_index = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<img data-src="/2023/11/02/2023-11-03-sentiment-analysis/step_1_for_sentiment_analysis.png" class="" width="600">
<p style="text-align:center; color: grey;">
  <i>DataFrame of the scraped headlines</i>
</p>

<h2 id="Step-3-Generate-the-news-sentiment-score"><a href="#Step-3-Generate-the-news-sentiment-score" class="headerlink" title="Step 3. Generate the news sentiment score"></a>Step 3. Generate the news sentiment score</h2><p>This step will be fairly simple. We apply the <code>polarity_scores()</code> function to all the headlines. Once we get all the negative, neutral, positive, and compound scores, we concatenate them back to the original news dataframe. Notice, here we need to download the <code>vader_lexicon</code> first so that the <code>polarity_scores()</code> function can work properly. The way that vader package calculates the score is quite interesting and not difficult to understand. If you are interested in knowing how the scores get calculated, read the <a target="_blank" rel="noopener" href="https://www.nltk.org/_modules/nltk/sentiment/vader.html">VADER source code</a>. Probably will take you half an hour to do so, but it will definitely pay off.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">nltk.download(<span class="string">&#x27;vader_lexicon&#x27;</span>)</span><br><span class="line">vader = SentimentIntensityAnalyzer()</span><br><span class="line"></span><br><span class="line">scored_news = news.join(pd.DataFrame(news[<span class="string">&#x27;Headline&#x27;</span>].apply(vader.polarity_scores).tolist()))</span><br></pre></td></tr></table></figure>
<img data-src="/2023/11/02/2023-11-03-sentiment-analysis/step_2_for_sentiment_analysis.png" class="" width="600">
<p style="text-align:center; color: grey;">
  <i>Attach the score back to the original DataFrame</i>
</p>

<h2 id="Step-4-To-further-add-a-flavor-to-the-sentiment-score"><a href="#Step-4-To-further-add-a-flavor-to-the-sentiment-score" class="headerlink" title="Step 4. To further add a flavor to the sentiment score"></a>Step 4. To further add a flavor to the sentiment score</h2><p>It is kind of a well-known fact that the impact influence of any newly released news will wane away as time passes. I use the EMA (Exponential Moving Average) method to factor this phenomenon into our sentiment score model. Here I adopt the 5-day EMA to calculate the sentiment score moving average.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">news_score = scored_news.loc[:, [<span class="string">&#x27;Ticker&#x27;</span>, <span class="string">&#x27;Date&#x27;</span>, <span class="string">&#x27;compound&#x27;</span>]].pivot_table(values=<span class="string">&#x27;compound&#x27;</span>, index=<span class="string">&#x27;Date&#x27;</span>, columns=<span class="string">&#x27;Ticker&#x27;</span>, aggfunc=<span class="string">&#x27;mean&#x27;</span>).ewm(<span class="number">5</span>).mean()</span><br><span class="line">news_score.dropna().plot()</span><br></pre></td></tr></table></figure>
<img data-src="/2023/11/02/2023-11-03-sentiment-analysis/step_3_for_sentiment_analysis.png" class="" width="600">
<p style="text-align:center; color: grey;">
  <i>5-day EMA of the sentiment scores</i>
</p>

<p>By looking at the diagram above, it is easy to notice that the sentiment score of these four tickers ended up having different moving paths. However, the stock prices are not driven by the exact score but by the relative changes in the scores. Therefore, let’s take one more step to find out the changes in the emotional implications of these headlines.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">news_score.pct_change().dropna().plot()</span><br></pre></td></tr></table></figure>
<img data-src="/2023/11/02/2023-11-03-sentiment-analysis/step_4_for_sentiment_analysis.png" class="" width="600">
<p style="text-align:center; color: grey;">
  <i>Percentage change of the daily sentiment score of each ticker</i>
</p>

<p>After these many steps, the outcome became much more clear at last. Both <code>BABA</code> and <code>NVDA</code> have positive changes in terms of the sentiment score changes. This might indicate that the stock prices of these two stocks possibly will have a positive influence and the demand of these two stocks would rise against the supply, leading the stock prices to go up.</p>
<h1 id="Conclusion-and-other-thoughts"><a href="#Conclusion-and-other-thoughts" class="headerlink" title="Conclusion and other thoughts"></a>Conclusion and other thoughts</h1><p>This is the end of my sentiment analysis, but it shouldn’t be yours. There are actually more interesting things and ideas you can start building based on this sentiment framework, such as:</p>
<ul>
<li>Find a suitable lexicon when processing your token and when evaluating your scores.</li>
<li>Scrape not just the headline of the news but also the content of the news to run a much more detailed sentimental analysis.</li>
<li>Send the news_score data into the LSTM model instead of simply using the Exponential Moving Average.</li>
<li>…</li>
</ul>
<p>Welcome leaving a message to me telling me whether you like this article or not. Or, maybe just tell me what can be added to the analysis here.<br>Cheers.</p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li><a target="_blank" rel="noopener" href="https://www.youtube.com/playlist?list=PLeo1K3hjS3uuvuAXhYjV2lMEShq2UYSwX">NLP Tutorial Python Youtube channel</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.datadriveninvestor.com/sentiment-analysis-of-stocks-from-financial-news-using-python-82ebdcefb638">Sentiment Analysis of Stocks from Financial News using Python</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/@mystery0116/nlp-how-does-nltk-vader-calculate-sentiment-6c32d0f5046b">NLP: How does NLTK.Vader Calculate Sentiment?</a></li>
<li><a target="_blank" rel="noopener" href="https://www.datacamp.com/tutorial/stemming-lemmatization-python">Stemming and Lemmatization in Python</a></li>
</ul>

    </div>
    
      
    
      
    

    
    
    
        <div class="reward-container">
  <div>Enjoy reading? Some donations would motivate me to produce more quality content</div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    Tip
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechatpay.png" alt="Michael Hsia WeChat Pay">
        <p>WeChat Pay</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/images/alipay.png" alt="Michael Hsia Alipay">
        <p>Alipay</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/images/stripe.png" alt="Michael Hsia Stripe">
        <p>Stripe</p>
      </div>

  </div>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Scrapy/" rel="tag"># Scrapy</a>
              <a href="/tags/Research/" rel="tag"># Research</a>
              <a href="/tags/Technical-Analysis/" rel="tag"># Technical Analysis</a>
              <a href="/tags/Python3/" rel="tag"># Python3</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2023/08/31/2023-08-31-backtrader-multistocks-backtesting/" rel="prev" title="【How 2】 Upgrade your backtesting arsenal - trading multiple stocks with "backtrader"">
      <i class="fa fa-chevron-left"></i> 【How 2】 Upgrade your backtesting arsenal - trading multiple stocks with "backtrader"
    </a></div>
      <div class="post-nav-item">
    <a href="/2024/01/18/2024-01-18-Revisit-Buy-On-Gao-Strategy/" rel="next" title="From Theory to Profits - Elevating the Buy-on-Gap Strategy with Advanced Techniques">
      From Theory to Profits - Elevating the Buy-on-Gap Strategy with Advanced Techniques <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#What-is-Sentiment-Analysis"><span class="nav-number">1.</span> <span class="nav-text">What is Sentiment Analysis</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#What-is-the-application-of-Sentiment-Analysis-in-the-financial-market"><span class="nav-number">2.</span> <span class="nav-text">What is the application of Sentiment Analysis in the financial market</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#NLP-Introduction"><span class="nav-number">3.</span> <span class="nav-text">NLP Introduction</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Tokenization"><span class="nav-number">3.1.</span> <span class="nav-text">Tokenization</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Stemming-amp-Lemmatization"><span class="nav-number">3.2.</span> <span class="nav-text">Stemming &amp; Lemmatization</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Part-of-speech-tagging"><span class="nav-number">3.3.</span> <span class="nav-text">Part-of-speech tagging</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#NER-Named-Entity-Recognition-and-chunking"><span class="nav-number">3.4.</span> <span class="nav-text">NER (Named Entity Recognition) and chunking</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#VADER-Valence-Aware-Dictionary-and-sEntiment-Reasoner"><span class="nav-number">4.</span> <span class="nav-text">VADER (Valence Aware Dictionary and sEntiment Reasoner)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Get-started-with-the-stock-sentiment-analysis"><span class="nav-number">5.</span> <span class="nav-text">Get started with the stock sentiment analysis</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Step-1-Global-variables"><span class="nav-number">5.1.</span> <span class="nav-text">Step 1. Global variables</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Step-2-Fetch-the-headlines-of-the-tickers"><span class="nav-number">5.2.</span> <span class="nav-text">Step 2. Fetch the headlines of the tickers</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Step-3-Generate-the-news-sentiment-score"><span class="nav-number">5.3.</span> <span class="nav-text">Step 3. Generate the news sentiment score</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Step-4-To-further-add-a-flavor-to-the-sentiment-score"><span class="nav-number">5.4.</span> <span class="nav-text">Step 4. To further add a flavor to the sentiment score</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Conclusion-and-other-thoughts"><span class="nav-number">6.</span> <span class="nav-text">Conclusion and other thoughts</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Reference"><span class="nav-number">7.</span> <span class="nav-text">Reference</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Michael Hsia</p>
  <div class="site-description" itemprop="description">Free your potential with learning for the rest of your life</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">58</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">21</span>
        <span class="site-state-item-name">tags</span></a>
      </div>

  </nav>
    

  <div class="">

    <div class="">

        <div class="social-item">
          <a target="_blank" class="social-link" href="/atom.xml">
            <span class="icon">
              <i class="fa fa-rss"></i>
            </span>

            <span class="label">RSS</span>
          </a>
        </div>
    </div>
  </div>

</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Michael Hsia</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

        
<div class="busuanzi-count">
  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/valine@1/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'xqc1TRzBeSqWMcMIO6i05hrV-MdYXbMMI',
      appKey     : '8y8oPqyB7YE9KwpM33MRijdR',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : true,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : 'https://xqc1trzb.api.lncldglobal.com'
    });
  }, window.Valine);
});
</script>

</body>
</html>
